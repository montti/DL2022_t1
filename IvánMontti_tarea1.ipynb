{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iván_Montti-Tarea1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 1 - Deep Learning - Iván Montti\n",
        "\n",
        "\n",
        "\n",
        "Imports"
      ],
      "metadata": {
        "id": "oACTm9PBlDB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TRgmpx37qRYB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,Flatten,Dropout, MaxPool2D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentación de Data Set"
      ],
      "metadata": {
        "id": "DvcCy-2rlJx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se debe indicar el camino a los archivos en el GDrive o dejarse en blaco si fueron cargados en /content \n",
        "path = \"drive/MyDrive/DL/\"\n",
        "\n",
        "# Cargamos los datos de entrenamiento desde el GDrive\n",
        "data = np.load(path + \"data_train.pkl\",allow_pickle=True,encoding='latin1')\n",
        "\n",
        "# Manipulamos la forma de los datos \n",
        "images_temp = data['temp_images'].reshape(-1,21,21,1)\n",
        "images_sci = data['sci_images'].reshape(-1,21,21,1)\n",
        "images_diff = data['diff_images'].reshape(-1,21,21,1)\n",
        "images_SNR = data['SNR_images'].reshape(-1,21,21,1)\n",
        "\n",
        "# Concatenamos las imagenes\n",
        "images = np.concatenate((images_temp, images_sci, images_diff, images_SNR), axis=3)\n",
        "\n",
        "# Augmentamos el dataset rotando y concatenado las imagenes en 90º, 180º y 270º \n",
        "images = np.concatenate((images, np.rot90(images, axes=(1,2)), np.rot90(images, k=2, axes=(1,2)), np.rot90(images, k=3, axes=(1,2))))\n",
        "\n",
        "# Obtenemos las labels y las concatenamos consigo mismas para mantener el formato anterior\n",
        "y = data['labels'].reshape(-1,1)\n",
        "y = np.concatenate((y,y,y,y))\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Dejamos un tercio de los datos para validacion\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, y, test_size=0.33, random_state=43)"
      ],
      "metadata": {
        "id": "ho_TgH8l7jNi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "VxQPKhyGlzaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicializamos el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadimos las capas\n",
        "model.add(Conv2D(filters = 4,kernel_size = 1,input_shape = (21,21,4)))\n",
        "model.add(Conv2D(8, 2, activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Conv2D(16, 2, activation='relu'))\n",
        "model.add(Conv2D(16, 2, activation='relu'))\n",
        "model.add(MaxPool2D(2, 2))\n",
        "model.add(Conv2D(32, 2, activation='relu'))\n",
        "model.add(Conv2D(32, 2, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=16,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=8,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 2,activation = 'softmax'))\n",
        "\n",
        "# Utilizamos RMSprop como optimizador y MSE como Loss Function\n",
        "# Con tamaño de batch 128 y 12 para las epochs \n",
        "model.compile(optimizer = 'RMSprop',loss = 'mse',metrics = ['mse', 'acc'])\n",
        "history = model.fit(x = X_train , y = y_train, batch_size = 128, epochs = 12, validation_data = (X_val,y_val))"
      ],
      "metadata": {
        "id": "HY4LEl1v7r6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95aba75d-ce1f-4a6d-f0af-4dafc9bfac8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "85/85 [==============================] - 12s 20ms/step - loss: 0.1166 - mse: 0.1166 - acc: 0.8365 - val_loss: 0.0326 - val_mse: 0.0326 - val_acc: 0.9611\n",
            "Epoch 2/12\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.0461 - mse: 0.0461 - acc: 0.9470 - val_loss: 0.0271 - val_mse: 0.0271 - val_acc: 0.9667\n",
            "Epoch 3/12\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.0338 - mse: 0.0338 - acc: 0.9632 - val_loss: 0.0316 - val_mse: 0.0316 - val_acc: 0.9633\n",
            "Epoch 4/12\n",
            "85/85 [==============================] - 1s 14ms/step - loss: 0.0293 - mse: 0.0293 - acc: 0.9664 - val_loss: 0.0213 - val_mse: 0.0213 - val_acc: 0.9742\n",
            "Epoch 5/12\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.0257 - mse: 0.0257 - acc: 0.9715 - val_loss: 0.0194 - val_mse: 0.0194 - val_acc: 0.9769\n",
            "Epoch 6/12\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.0236 - mse: 0.0236 - acc: 0.9748 - val_loss: 0.0201 - val_mse: 0.0201 - val_acc: 0.9776\n",
            "Epoch 7/12\n",
            "85/85 [==============================] - 1s 14ms/step - loss: 0.0217 - mse: 0.0217 - acc: 0.9758 - val_loss: 0.0210 - val_mse: 0.0210 - val_acc: 0.9742\n",
            "Epoch 8/12\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.0226 - mse: 0.0226 - acc: 0.9744 - val_loss: 0.0164 - val_mse: 0.0164 - val_acc: 0.9814\n",
            "Epoch 9/12\n",
            "85/85 [==============================] - 1s 13ms/step - loss: 0.0197 - mse: 0.0197 - acc: 0.9786 - val_loss: 0.0190 - val_mse: 0.0190 - val_acc: 0.9767\n",
            "Epoch 10/12\n",
            "85/85 [==============================] - 1s 15ms/step - loss: 0.0189 - mse: 0.0189 - acc: 0.9789 - val_loss: 0.0181 - val_mse: 0.0181 - val_acc: 0.9804\n",
            "Epoch 11/12\n",
            "85/85 [==============================] - 1s 14ms/step - loss: 0.0179 - mse: 0.0179 - acc: 0.9811 - val_loss: 0.0192 - val_mse: 0.0192 - val_acc: 0.9784\n",
            "Epoch 12/12\n",
            "85/85 [==============================] - 1s 14ms/step - loss: 0.0174 - mse: 0.0174 - acc: 0.9812 - val_loss: 0.0163 - val_mse: 0.0163 - val_acc: 0.9812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen de modelo"
      ],
      "metadata": {
        "id": "AFXD_1M1qVXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkm9uLrGqYW1",
        "outputId": "31880c37-b48c-452e-dd82-7182996c03fe"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 21, 21, 4)         20        \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 20, 20, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 10, 10, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 9, 9, 16)          528       \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 8, 8, 16)          1040      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 4, 4, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 3, 3, 32)          2080      \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 2, 2, 32)          4128      \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 16)                2064      \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,150\n",
            "Trainable params: 10,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metricas"
      ],
      "metadata": {
        "id": "T4K9hWgsl3Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "y_test = np.argmax(model.predict(X_val),-1)\n",
        "y_pred = np.argmax(y_val,-1)\n",
        "\n",
        "print(\"accuracy:\\t\", accuracy_score (y_test, y_pred))\n",
        "print( \"precision:\\t\", precision_score (y_test, y_pred, average = 'macro'))\n",
        "print(\"recall:\\t\\t\", recall_score (y_test, y_pred, average = 'macro'))\n",
        "print( \"f1:\\t\\t\", f1_score (y_test, y_pred, average = 'macro'))"
      ],
      "metadata": {
        "id": "rArVfUKC72YZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd92a57e-ba66-4d91-decb-9a54ff457c7c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:\t 0.9825023518344309\n",
            "precision:\t 0.9824495350830822\n",
            "recall:\t\t 0.9825508332490351\n",
            "f1:\t\t 0.9824942983710749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test y normalización "
      ],
      "metadata": {
        "id": "2GKbbiUJmFCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los datos de testeo y los manipulamos como los datos de entrenamiento \n",
        "data_test = np.load(path + \"unlab_test.pkl\",allow_pickle=True,encoding='latin1')\n",
        "\n",
        "images_test_temp = data_test['temp_images'].reshape(-1,21,21,1)\n",
        "images_test_sci = data_test['sci_images'].reshape(-1,21,21,1)\n",
        "images_test_diff = data_test['diff_images'].reshape(-1,21,21,1)\n",
        "images_test_SNR = data_test['SNR_images'].reshape(-1,21,21,1)\n",
        "\n",
        "images_test = np.concatenate((images_test_temp, images_test_sci, images_test_diff, images_test_SNR), axis=3)\n",
        "\n",
        "y_test = np.argmax(y_test,-1)"
      ],
      "metadata": {
        "id": "tFtJaDz68Jb5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportación"
      ],
      "metadata": {
        "id": "_8HBsue9pnOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza el formato indicado en la ayudantia\n",
        "data_out = {'ID': data_test['ID'], 'predicted':y_test}\n",
        "df_out = pd.DataFrame(data_out)\n",
        "df_out.to_csv (\"predicted.csv\",index=False)"
      ],
      "metadata": {
        "id": "mum1FH0D8Xj6"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}